{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as F\n\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-08T19:24:40.825880Z","iopub.execute_input":"2023-04-08T19:24:40.826281Z","iopub.status.idle":"2023-04-08T19:24:43.453014Z","shell.execute_reply.started":"2023-04-08T19:24:40.826246Z","shell.execute_reply":"2023-04-08T19:24:43.451961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Critic(nn.Module):\n    def __init__(self, channels_img, features_d):\n        super(Critic, self).__init__()\n        self.critic = nn.Sequential(\n            #Input = Nxchannels_imgx64x64\n            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n\n            self._block(features_d, features_d*2, 4, 2, 1), #Nxfeatures_d*2x32x32\n            self._block(features_d*2, features_d*4, 4, 2, 1), #Nxfeatures_d*4x16x16\n            self._block(features_d*4, features_d*8, 4, 2, 1), #Nxfeatures_d*8x8x8\n            self._block(features_d*8, features_d*16, 4, 2, 1), #Nxfeatures_d*16x4x4\n\n            nn.Conv2d(features_d*16, 1, kernel_size=4, stride=2, padding=1), #Nx1x4x4\n            ## Note: No sigmoid here\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias = False,),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(0.2),\n        )\n    \n    def forward(self, x):\n        return self.critic(x)\n    \nclass Generator(nn.Module):\n    def __init__(self, z_dim, channels_img, features_g):\n        super(Generator, self).__init__()\n        self.gen = nn.Sequential(\n            #Input = N*z_dim*1*1\n            self._block(z_dim, features_g*16, 4, 1, 0), #N*features_g*16*4*4\n            self._block(features_g*16, features_g*8, 4, 2, 1), #N*features_g*8*8*8\n            self._block(features_g*8, features_g*4, 4, 2, 1), #N*features_g*4*16*16\n            self._block(features_g*4, features_g*2, 4, 2, 1), #N*features_g*2*32*32\n            nn.ConvTranspose2d(features_g*2, channels_img, kernel_size=4, stride=2, padding=1), #N*channels_img*64*64\n            nn.Tanh(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias = False,),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n    \n    def forward(self, x):\n        return self.gen(x)\n\ndef initialize_weights(model):\n    for m in model.modules():\n        if isinstance(m , (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:24:43.454829Z","iopub.execute_input":"2023-04-08T19:24:43.455362Z","iopub.status.idle":"2023-04-08T19:24:43.471154Z","shell.execute_reply.started":"2023-04-08T19:24:43.455332Z","shell.execute_reply":"2023-04-08T19:24:43.469262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nlr = 5e-5 #vary \nz_dim = 100 #vary\nimg_dim = 64\nchannels_img = 1\nbatch_size = 64\nnum_epochs = 50\nfeatures_d = 64\nfeatures_g = 64\n\ncritic_iter = 5\nweight_clip = 0.01","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:24:43.472965Z","iopub.execute_input":"2023-04-08T19:24:43.473539Z","iopub.status.idle":"2023-04-08T19:24:43.541464Z","shell.execute_reply.started":"2023-04-08T19:24:43.473503Z","shell.execute_reply":"2023-04-08T19:24:43.540362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformation = transforms.Compose(\n    [\n        transforms.Resize(img_dim),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5 for _ in range(channels_img)],[0.5 for _ in range(channels_img)]),     \n    ]\n) \n\ndataset = datasets.MNIST(root = \"dataset\", transform = transformation, download = True)\nloader = DataLoader(dataset, batch_size=batch_size, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:24:43.544303Z","iopub.execute_input":"2023-04-08T19:24:43.544823Z","iopub.status.idle":"2023-04-08T19:24:44.621393Z","shell.execute_reply.started":"2023-04-08T19:24:43.544786Z","shell.execute_reply":"2023-04-08T19:24:44.620336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"critic = Critic(channels_img, features_d).to(device)\ngen = Generator(z_dim, channels_img, features_g).to(device)\n\ninitialize_weights(critic)\ninitialize_weights(gen)\n\nopt_critic = optim.RMSprop(critic.parameters(), lr = lr)\nopt_gen = optim.RMSprop(gen.parameters(), lr = lr)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:24:44.622830Z","iopub.execute_input":"2023-04-08T19:24:44.623293Z","iopub.status.idle":"2023-04-08T19:24:47.708141Z","shell.execute_reply.started":"2023-04-08T19:24:44.623255Z","shell.execute_reply":"2023-04-08T19:24:47.707059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fixed_noise = torch.randn((32, z_dim, 1, 1)).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:24:47.709598Z","iopub.execute_input":"2023-04-08T19:24:47.709953Z","iopub.status.idle":"2023-04-08T19:24:47.718544Z","shell.execute_reply.started":"2023-04-08T19:24:47.709911Z","shell.execute_reply":"2023-04-08T19:24:47.716866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show(imgs): #Show function from pytorch.org\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n    for i, img in enumerate(imgs):\n        img = img.detach()\n        img = F.to_pil_image(img)\n        axs[0, i].imshow(np.asarray(img))\n        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:24:47.721280Z","iopub.execute_input":"2023-04-08T19:24:47.721969Z","iopub.status.idle":"2023-04-08T19:24:47.728873Z","shell.execute_reply.started":"2023-04-08T19:24:47.721934Z","shell.execute_reply":"2023-04-08T19:24:47.727842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    for batch_idx, (real, _) in enumerate(loader):\n        real = real.to(device)\n        batch_size = real.shape[0]\n        \n        # Train Critic Max E[critic(real)] - E[critic(fake)]\n        for _ in range(critic_iter):\n            noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n            fake = gen(noise)\n\n            critic_real = critic(real).reshape(-1)\n            critic_fake = critic(fake).reshape(-1)\n            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n\n            critic.zero_grad()\n            loss_critic.backward(retain_graph = True)# a\n            opt_critic.step()\n\n            for para in critic.parameters():\n                para.data.clamp_(-weight_clip, weight_clip)\n\n        # Train Gen Min -E[critic(fake)]\n\n        output = critic(fake).reshape(-1)\n        loss_gen = -torch.mean(output)\n\n        gen.zero_grad()\n        loss_gen.backward(retain_graph = True)# a\n        opt_gen.step()\n\n\n###################################################\n        if (batch_idx == 0):\n            print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\Loss Critic: {loss_critic:.4f}, loss Generator: {loss_gen:.4f}\")\n\n            if (batch_idx == 0):\n                with torch.no_grad():\n                    fake = gen(fixed_noise).reshape(-1, channels_img, img_dim, img_dim)\n                    img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n                    show(img_grid_fake)\n####################################################","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:24:47.731105Z","iopub.execute_input":"2023-04-08T19:24:47.731874Z","iopub.status.idle":"2023-04-08T20:09:44.101591Z","shell.execute_reply.started":"2023-04-08T19:24:47.731825Z","shell.execute_reply":"2023-04-08T20:09:44.100495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}